{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "mount_file_id": "1YA_HCTYNHCiJrIKI5asY5FoDEIz7oISs",
      "authorship_tag": "ABX9TyPes8ju+f5EQljcr0m48JVJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya4131/csc4343-homework1/blob/main/4343homework1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zjA2bA9UZ6Hk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "'''\n",
        "You need to implement:\n",
        "\n",
        "class ResSect(nn.Module):\n",
        "    def __init__(self, n_filter, n_residual_blocks, beginning_stride):\n",
        "        Initialize the sector by creating layers needed\n",
        "        n_filter: number of filters in the conv layers in the blocks\n",
        "        n_residual_blocks: number of blocks in this sector\n",
        "        beginning_stride: the stride of the first conv of the first block in the sector\n",
        "\n",
        "    def forward(self, x):\n",
        "        Implement computation performed in the sector\n",
        "        x: input tensor\n",
        "        You should return the result tensor\n",
        "'''\n",
        "\n",
        "class ResSect(nn.Module):\n",
        "    def __init__(self, in_channels, n_residual_blocks, beginning_stride):\n",
        "        super().__init__()\n",
        "\n",
        "        strides = [beginning_stride] + [1] * (n_residual_blocks - 1)\n",
        "        out_channels = in_channels\n",
        "        if in_channels == 64 or in_channels == 128:\n",
        "            in_channels = in_channels // 2\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            print(in_channels, out_channels, beginning_stride)\n",
        "            layers.append(ResBlock(in_channels, out_channels, beginning_stride))\n",
        "            in_channels = out_channels\n",
        "        self.blocks = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.blocks(x)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, beginning_stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels,\n",
        "                      out_channels,\n",
        "                      kernel_size=3,\n",
        "                      padding=1,\n",
        "                      stride=beginning_stride),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2_layer = nn.Sequential(\n",
        "            nn.Conv2d(out_channels,\n",
        "                      out_channels,\n",
        "                      kernel_size=3,\n",
        "                      padding=1,\n",
        "                      stride=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.relu_layer = nn.ReLU()\n",
        "\n",
        "        self.downsample_layer = nn.Sequential()\n",
        "        if beginning_stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                          stride=beginning_stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.conv1_layer(x)\n",
        "        x = self.conv2_layer(x)\n",
        "        x += self.downsample_layer(residual)\n",
        "        x = self.relu_layer(x)\n",
        "        return x\n",
        "\n",
        "class ResModel(nn.Module):\n",
        "    def __init__(self, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.sect1 = ResSect(32, 3, 1)\n",
        "        self.sect2 = ResSect(64, 3, 2)\n",
        "        self.sect3 = ResSect(128, 3, 2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 10)\n",
        "\n",
        "        if pretrained:\n",
        "            self.load_trained_model()\n",
        "\n",
        "    def load_trained_model(self):\n",
        "        '''\n",
        "        You need to implement this function to:\n",
        "            1. download the saved pretrained model from your online location\n",
        "            2. load model from the downloaded model file\n",
        "        '''\n",
        "\n",
        "        print(\"Downloading\")\n",
        "        request = requests.get(\"https://github.com/aditya4131/csc4343-homework1/raw/main/model-3.pth\")\n",
        "        with open(\"model-3.pth\", \"wb\") as f:\n",
        "            f.write(request.content)\n",
        "\n",
        "        return self.load_state_dict(torch.load(\"model-3.pth\"))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.sect1(x)\n",
        "        x = self.sect2(x)\n",
        "        x = self.sect3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "device = 'cuda'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlaaGD78Z-4B",
        "outputId": "da22daa5-fb5e-45b0-f3e1-0c3a794eee43"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResModel().to(device)"
      ],
      "metadata": {
        "id": "VclJWrWobOg4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) * 100\n",
        "  return acc\n",
        "\n",
        "\n",
        "def train_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device:torch.device):\n",
        "  train_loss, train_acc = 0,0\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "    optimizer.zero_grad()\n",
        "    # loss.requires_grad = True\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "\n",
        "  print(f\"Train loss: {train_loss} | Train accuracy: {train_acc}\")\n",
        "\n",
        "def test_step(model:torch.nn.Module,\n",
        "              dataloader:torch.utils.data.DataLoader,\n",
        "              loss_fn:torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device:torch.device):\n",
        "  test_loss, test_acc = 0,0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_pred = model(X)\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      test_loss += loss\n",
        "      test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "      optimizer.zero_grad()\n",
        "      loss.requires_grad = True\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    test_loss /= len(dataloader)\n",
        "    test_acc /= len(dataloader)\n",
        "\n",
        "    print(f\"Train loss: {test_loss} | Train accuracy: {test_acc}\")\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lr=0.00001, params=model.parameters())\n"
      ],
      "metadata": {
        "id": "ERrT-ig9bTmD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 70\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_step(model=model,\n",
        "             dataloader=trainloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "  test_step(model=model,\n",
        "             dataloader=trainloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)"
      ],
      "metadata": {
        "id": "oRdk-A4ZcwY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa36a865-8432-48d2-eb0f-c1e5b081adda"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 2.0007381439208984 | Train accuracy: 26.973305626598467\n",
            "Train loss: 1.7119922637939453 | Train accuracy: 37.71539322250639\n",
            "Train loss: 1.6071504354476929 | Train accuracy: 41.47818094629156\n",
            "Train loss: 1.5085219144821167 | Train accuracy: 44.790201406649615\n",
            "Train loss: 1.4498095512390137 | Train accuracy: 47.25863171355499\n",
            "Train loss: 1.3823585510253906 | Train accuracy: 50.0147858056266\n",
            "Train loss: 1.3465465307235718 | Train accuracy: 51.283168158567776\n",
            "Train loss: 1.2933015823364258 | Train accuracy: 53.33639705882353\n",
            "Train loss: 1.2688267230987549 | Train accuracy: 54.41496163682864\n",
            "Train loss: 1.2201076745986938 | Train accuracy: 56.25439578005115\n",
            "Train loss: 1.2062830924987793 | Train accuracy: 56.755514705882355\n",
            "Train loss: 1.167755126953125 | Train accuracy: 58.161365089514064\n",
            "Train loss: 1.1544277667999268 | Train accuracy: 58.77038043478261\n",
            "Train loss: 1.1196249723434448 | Train accuracy: 60.15265345268542\n",
            "Train loss: 1.1105080842971802 | Train accuracy: 60.52789322250639\n",
            "Train loss: 1.0747406482696533 | Train accuracy: 61.796275575447574\n",
            "Train loss: 1.070535659790039 | Train accuracy: 61.96131713554987\n",
            "Train loss: 1.0420271158218384 | Train accuracy: 63.02070012787724\n",
            "Train loss: 1.0354126691818237 | Train accuracy: 63.40632992327366\n",
            "Train loss: 1.0026613473892212 | Train accuracy: 64.53125\n",
            "Train loss: 0.9996615052223206 | Train accuracy: 64.60038363171356\n",
            "Train loss: 0.9654122591018677 | Train accuracy: 66.09215153452685\n",
            "Train loss: 0.967429518699646 | Train accuracy: 66.01382672634271\n",
            "Train loss: 0.9353350400924683 | Train accuracy: 67.37412084398977\n",
            "Train loss: 0.9341374635696411 | Train accuracy: 67.13315217391305\n",
            "Train loss: 0.9049166440963745 | Train accuracy: 68.56897378516624\n",
            "Train loss: 0.9073184728622437 | Train accuracy: 68.35717710997443\n",
            "Train loss: 0.8765770196914673 | Train accuracy: 69.49328644501279\n",
            "Train loss: 0.8784540295600891 | Train accuracy: 69.26430626598466\n",
            "Train loss: 0.8482025861740112 | Train accuracy: 70.73529411764706\n",
            "Train loss: 0.851431667804718 | Train accuracy: 70.60182225063939\n",
            "Train loss: 0.8205723762512207 | Train accuracy: 71.83863491048594\n",
            "Train loss: 0.8240841031074524 | Train accuracy: 71.68518222506394\n",
            "Train loss: 0.793664276599884 | Train accuracy: 72.83407928388746\n",
            "Train loss: 0.796576738357544 | Train accuracy: 72.7653452685422\n",
            "Train loss: 0.7660545110702515 | Train accuracy: 74.22274616368287\n",
            "Train loss: 0.773402750492096 | Train accuracy: 73.71323529411765\n",
            "Train loss: 0.7420446872711182 | Train accuracy: 75.36524936061382\n",
            "Train loss: 0.7478696703910828 | Train accuracy: 74.66312340153452\n",
            "Train loss: 0.7131739258766174 | Train accuracy: 76.24040920716112\n",
            "Train loss: 0.7229200005531311 | Train accuracy: 75.67575127877238\n",
            "Train loss: 0.6926050186157227 | Train accuracy: 77.02046035805627\n",
            "Train loss: 0.699596107006073 | Train accuracy: 76.50255754475704\n",
            "Train loss: 0.6683571934700012 | Train accuracy: 77.85246163682865\n",
            "Train loss: 0.6742838621139526 | Train accuracy: 77.59071291560102\n",
            "Train loss: 0.6424942016601562 | Train accuracy: 78.83032289002557\n",
            "Train loss: 0.6518362760543823 | Train accuracy: 78.55738491048594\n",
            "Train loss: 0.6246678233146667 | Train accuracy: 79.67910805626599\n",
            "Train loss: 0.6277599334716797 | Train accuracy: 79.38658887468031\n",
            "Train loss: 0.5981786847114563 | Train accuracy: 80.80962276214834\n",
            "Train loss: 0.608152449131012 | Train accuracy: 80.22778132992327\n",
            "Train loss: 0.5731592178344727 | Train accuracy: 81.79627557544757\n",
            "Train loss: 0.581443727016449 | Train accuracy: 81.16687979539643\n",
            "Train loss: 0.5533829927444458 | Train accuracy: 82.497202685422\n",
            "Train loss: 0.5631948113441467 | Train accuracy: 82.00287723785166\n",
            "Train loss: 0.5296126008033752 | Train accuracy: 83.36516943734016\n",
            "Train loss: 0.5405369997024536 | Train accuracy: 82.79092071611254\n",
            "Train loss: 0.5108795762062073 | Train accuracy: 83.94661125319693\n",
            "Train loss: 0.5201320648193359 | Train accuracy: 83.64370204603581\n",
            "Train loss: 0.4888765215873718 | Train accuracy: 84.97682225063939\n",
            "Train loss: 0.4981515407562256 | Train accuracy: 84.42295396419438\n",
            "Train loss: 0.46674129366874695 | Train accuracy: 85.82680626598466\n",
            "Train loss: 0.47585609555244446 | Train accuracy: 85.37963554987212\n",
            "Train loss: 0.4483977258205414 | Train accuracy: 86.63523017902813\n",
            "Train loss: 0.4536280035972595 | Train accuracy: 86.22322570332481\n",
            "Train loss: 0.42896193265914917 | Train accuracy: 87.32177109974424\n",
            "Train loss: 0.43510106205940247 | Train accuracy: 87.01086956521739\n",
            "Train loss: 0.40263012051582336 | Train accuracy: 88.63011508951406\n",
            "Train loss: 0.41877827048301697 | Train accuracy: 87.5647378516624\n",
            "Train loss: 0.3854365646839142 | Train accuracy: 89.10246163682865\n",
            "Train loss: 0.3990600109100342 | Train accuracy: 88.33799552429667\n",
            "Train loss: 0.3681858479976654 | Train accuracy: 89.76062979539643\n",
            "Train loss: 0.37697988748550415 | Train accuracy: 89.27669437340154\n",
            "Train loss: 0.35165897011756897 | Train accuracy: 90.47314578005115\n",
            "Train loss: 0.3565309941768646 | Train accuracy: 90.11269181585678\n",
            "Train loss: 0.32950788736343384 | Train accuracy: 91.34031329923273\n",
            "Train loss: 0.336341917514801 | Train accuracy: 90.95668158567774\n",
            "Train loss: 0.31205683946609497 | Train accuracy: 91.97690217391305\n",
            "Train loss: 0.3235776722431183 | Train accuracy: 91.25519501278772\n",
            "Train loss: 0.2935589849948883 | Train accuracy: 92.70859974424552\n",
            "Train loss: 0.3009721338748932 | Train accuracy: 92.14434143222506\n",
            "Train loss: 0.2799893319606781 | Train accuracy: 93.07424872122762\n",
            "Train loss: 0.284455269575119 | Train accuracy: 92.80250959079284\n",
            "Train loss: 0.2603660523891449 | Train accuracy: 93.73441496163683\n",
            "Train loss: 0.2719953954219818 | Train accuracy: 93.17095588235294\n",
            "Train loss: 0.24302560091018677 | Train accuracy: 94.41256393861893\n",
            "Train loss: 0.2540774643421173 | Train accuracy: 93.80075127877238\n",
            "Train loss: 0.22967086732387543 | Train accuracy: 94.86532928388746\n",
            "Train loss: 0.23670290410518646 | Train accuracy: 94.42774936061382\n",
            "Train loss: 0.2179878056049347 | Train accuracy: 95.20540281329923\n",
            "Train loss: 0.2256862372159958 | Train accuracy: 94.73545396419438\n",
            "Train loss: 0.19981956481933594 | Train accuracy: 95.72890025575448\n",
            "Train loss: 0.21322475373744965 | Train accuracy: 95.17942774936061\n",
            "Train loss: 0.18601906299591064 | Train accuracy: 96.47298593350384\n",
            "Train loss: 0.1951064020395279 | Train accuracy: 95.89474104859335\n",
            "Train loss: 0.17744962871074677 | Train accuracy: 96.52453644501279\n",
            "Train loss: 0.18677544593811035 | Train accuracy: 96.02661445012788\n",
            "Train loss: 0.1652253121137619 | Train accuracy: 96.8042679028133\n",
            "Train loss: 0.1764037311077118 | Train accuracy: 96.36748721227622\n",
            "Train loss: 0.15645161271095276 | Train accuracy: 97.12436061381074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(torch.device('cpu'))\n",
        "torch.save(model.state_dict(), './model.pth')"
      ],
      "metadata": {
        "id": "PKEarRLQe732"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rIxSiAN53lG-"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}