{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "1YA_HCTYNHCiJrIKI5asY5FoDEIz7oISs",
      "authorship_tag": "ABX9TyMyTJpC7Is0g+XztOqXBeH9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya4131/csc4343-homework1/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zjA2bA9UZ6Hk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "'''\n",
        "You need to implement:\n",
        "\n",
        "class ResSect(nn.Module):\n",
        "    def __init__(self, n_filter, n_residual_blocks, beginning_stride):\n",
        "        Initialize the sector by creating layers needed\n",
        "        n_filter: number of filters in the conv layers in the blocks\n",
        "        n_residual_blocks: number of blocks in this sector\n",
        "        beginning_stride: the stride of the first conv of the first block in the sector\n",
        "\n",
        "    def forward(self, x):\n",
        "        Implement computation performed in the sector\n",
        "        x: input tensor\n",
        "        You should return the result tensor\n",
        "'''\n",
        "\n",
        "# class ResSect(nn.Module):\n",
        "#     def __init__(self, n_filter: int, n_residual_blocks:int, beginning_stride:int):\n",
        "#         super(ResSect, self).__init__()\n",
        "#         self.conv_layer_1 = nn.Conv2d(in_channels=n_filter,\n",
        "#                                       out_channels=n_filter,\n",
        "#                                       kernel_size=3,\n",
        "#                                       stride=beginning_stride,\n",
        "#                                       padding=1)\n",
        "#         self.batch_norm_1 = nn.BatchNorm2d(num_features=n_filter)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.conv_layer_2 = nn.Conv2d(in_channels=n_filter,\n",
        "#                                       out_channels=n_filter * 2,\n",
        "#                                       kernel_size=3,\n",
        "#                                       stride=beginning_stride,\n",
        "#                                       padding=1)\n",
        "#         self.batch_norm_2 = nn.BatchNorm2d(num_features=n_filter * 2)\n",
        "#         self.relu_2 = nn.ReLU()\n",
        "\n",
        "#         self.conv1x1 = nn.Conv2d(in_channels=n_filter,\n",
        "#                                  out_channels=n_filter,\n",
        "#                                  kernel_size=3,\n",
        "#                                  stride=beginning_stride,\n",
        "#                                  bias=False)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         residual = x\n",
        "#         x = self.conv_layer_1(x)\n",
        "#         x = self.batch_norm_1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.conv_layer_2(x)\n",
        "#         x = self.batch_norm_2(x)\n",
        "#         # residual = self.conv1x1(residual)\n",
        "#         # x += residual\n",
        "#         x = self.relu_2(x)\n",
        "#         return x\n",
        "\n",
        "class ResSect(nn.Module):\n",
        "    def __init__(self, n_filter, n_residual_blocks, beginning_stride):\n",
        "        super(ResSect, self).__init__()\n",
        "        self.blocks = nn.ModuleList([ResidualBlock(n_filter, beginning_stride if i == 0 else 1) for i in range(n_residual_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self.make_layer(32, 32, 3, stride=1)\n",
        "        self.layer2 = self.make_layer(32, 64, 3, stride=2)\n",
        "        self.layer3 = self.make_layer(64, 128, 3, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "            in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "device = 'cuda'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlaaGD78Z-4B",
        "outputId": "3ba208f1-6a87-431f-db85-292b3292e0a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResModel().to(device)"
      ],
      "metadata": {
        "id": "VclJWrWobOg4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) * 100\n",
        "  return acc\n",
        "\n",
        "\n",
        "def train_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device:torch.device):\n",
        "  train_loss, train_acc = 0,0\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "    optimizer.zero_grad()\n",
        "    # loss.requires_grad = True\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "\n",
        "  print(f\"Train loss: {train_loss} | Train accuracy: {train_acc}\")\n",
        "\n",
        "def test_step(model:torch.nn.Module,\n",
        "              dataloader:torch.utils.data.DataLoader,\n",
        "              loss_fn:torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device:torch.device):\n",
        "  test_loss, test_acc = 0,0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_pred = model(X)\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      test_loss += loss\n",
        "      test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "      optimizer.zero_grad()\n",
        "      loss.requires_grad = True\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    test_loss /= len(dataloader)\n",
        "    test_acc /= len(dataloader)\n",
        "\n",
        "    print(f\"Train loss: {test_loss} | Train accuracy: {test_acc}\")\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lr=0.00001, params=model.parameters())\n"
      ],
      "metadata": {
        "id": "ERrT-ig9bTmD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_step(model=model,\n",
        "             dataloader=trainloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "  test_step(model=model,\n",
        "             dataloader=trainloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)"
      ],
      "metadata": {
        "id": "oRdk-A4ZcwY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3bdab2-d486-45db-9811-66d8e1fd967e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.9152288436889648 | Train accuracy: 29.53005115089514\n",
            "Train loss: 1.674975037574768 | Train accuracy: 39.291480179028135\n",
            "Train loss: 1.564914584159851 | Train accuracy: 43.22010869565217\n",
            "Train loss: 1.4708609580993652 | Train accuracy: 46.67479219948849\n",
            "Train loss: 1.423284888267517 | Train accuracy: 48.355179028132994\n",
            "Train loss: 1.362485408782959 | Train accuracy: 50.627797314578004\n",
            "Train loss: 1.331389307975769 | Train accuracy: 51.80986253196931\n",
            "Train loss: 1.2818050384521484 | Train accuracy: 53.747202685421996\n",
            "Train loss: 1.2594236135482788 | Train accuracy: 54.740648976982094\n",
            "Train loss: 1.2173354625701904 | Train accuracy: 56.16847826086956\n",
            "Train loss: 1.1999412775039673 | Train accuracy: 56.819053708439895\n",
            "Train loss: 1.1608275175094604 | Train accuracy: 58.61812659846547\n",
            "Train loss: 1.1489020586013794 | Train accuracy: 58.871083759590796\n",
            "Train loss: 1.1111664772033691 | Train accuracy: 60.72010869565217\n",
            "Train loss: 1.1033157110214233 | Train accuracy: 60.760070332480815\n",
            "Train loss: 1.0744532346725464 | Train accuracy: 61.856218030690535\n",
            "Train loss: 1.0649694204330444 | Train accuracy: 62.34814578005115\n",
            "Train loss: 1.0360294580459595 | Train accuracy: 63.65169437340153\n",
            "Train loss: 1.0279204845428467 | Train accuracy: 63.67766943734016\n",
            "Train loss: 0.997016429901123 | Train accuracy: 64.70748081841433\n",
            "Train loss: 0.99370938539505 | Train accuracy: 65.06273976982096\n",
            "Train loss: 0.9613187909126282 | Train accuracy: 66.29315856777494\n",
            "Train loss: 0.9618828892707825 | Train accuracy: 66.24200767263427\n",
            "Train loss: 0.9296653270721436 | Train accuracy: 67.48201726342711\n",
            "Train loss: 0.927842378616333 | Train accuracy: 67.62108375959079\n",
            "Train loss: 0.9010013341903687 | Train accuracy: 68.80634590792839\n",
            "Train loss: 0.9015899300575256 | Train accuracy: 68.64729859335038\n",
            "Train loss: 0.8637085556983948 | Train accuracy: 70.24056905370844\n",
            "Train loss: 0.8703853487968445 | Train accuracy: 70.02597506393862\n",
            "Train loss: 0.8392828106880188 | Train accuracy: 71.15409207161126\n",
            "Train loss: 0.8434851765632629 | Train accuracy: 70.96747122762149\n",
            "Train loss: 0.812003493309021 | Train accuracy: 72.24624360613811\n",
            "Train loss: 0.8137625455856323 | Train accuracy: 71.98529411764706\n",
            "Train loss: 0.7812854051589966 | Train accuracy: 73.66807864450128\n",
            "Train loss: 0.7859765291213989 | Train accuracy: 73.17055626598466\n",
            "Train loss: 0.7559859752655029 | Train accuracy: 74.41376278772378\n",
            "Train loss: 0.7604244351387024 | Train accuracy: 74.19357416879795\n",
            "Train loss: 0.7363808155059814 | Train accuracy: 75.26054987212277\n",
            "Train loss: 0.7351314425468445 | Train accuracy: 75.1298753196931\n",
            "Train loss: 0.7036912441253662 | Train accuracy: 76.65041560102301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), './model.pth')"
      ],
      "metadata": {
        "id": "PKEarRLQe732"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rIxSiAN53lG-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}